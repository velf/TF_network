{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Network Analysis with Python\n",
    "\n",
    "\n",
    "\n",
    "<div class=\"frontmatter text-center\">\n",
    "<img src=\"network.png\" width=\"800px\"/>\n",
    "</div>\n",
    "\n",
    "NetworkX and IGraph are the most common tools in Python for Network Analysis. We will use [NetworkX](https://networkx.github.io/) in this class, because it has a much better Documentation.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"frontmatter text-center\">\n",
    "<img src=\"networkx.png\" width=\"800px\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More resources:\n",
    "- [PyCon Talk about Network Analysis](http://prezi.com/szsbgd2ortmu/?utm_campaign=share&utm_medium=copy&rc=ex0share)\n",
    "- [Filtering methods](https://github.com/velf/Network_Analytical_Notebooks/blob/master/Network_Projection_Filtering.ipynb)\n",
    "- [Interactive Network Visualization in Bokeh](https://github.com/blue-yonder/documents/tree/master/presentations/EuroPython%202016/networkx_visualization_powered_by_bokeh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import seaborn\n",
    "import pandas as pd\n",
    "import community\n",
    "from collections import Counter, defaultdict\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a graph from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G=nx.Graph()\n",
    "G.add_node(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,10):\n",
    "    G.add_node(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G.add_edge(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,8):\n",
    "    G.add_edge(i, i+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.density(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.degree(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use a bit more complicated data. We will use the Marvel superheroes network to investigate the capabilites of Networkx. \n",
    "\n",
    "Our to do:\n",
    "1. *Read and Parse the source files as bipartite network (marvel_heroes.nodes, marvel_issues.nodes) - done by me*\n",
    "2. Project it into superhero-superhero network\n",
    "3. Descriptive Statistics (density, degree ditribution)\n",
    "4. Filtering\n",
    "5. Community detection\n",
    "6. Visualization\n",
    "\n",
    "### The planned result is similar to this:\n",
    "\n",
    "<div class=\"frontmatter text-center\">\n",
    "<img src=\"network_of_marvel.jpg\" width=\"600px\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g=nx.Graph()\n",
    "heroes_ids= set()\n",
    "for line in open ('marvel_heroes.nodes'):\n",
    "    id, name = line.strip().split(' ', 1)\n",
    "    g.add_node(int(id), {'name': name.replace('\"', ''), 'bpartite': 0})\n",
    "    heroes_ids.add(int(id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "issues_ids= set()\n",
    "issue_name_to_id={}\n",
    "for line in open ('marvel_issues.nodes'):\n",
    "    id, name = line.strip().split(' ', 1)\n",
    "    g.add_node(int(id), {'name': name.replace('\"', ''), 'bpartite': 1})\n",
    "    issues_ids.add(int(id))\n",
    "    issue_name_to_id[name.replace('\"', '')]=int(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for line in open ('marvel.edges'):\n",
    "    ids = list(map(int, line.strip().split()))\n",
    "    from_id = ids[0]\n",
    "    for to_id in ids[1:]:\n",
    "        g.add_edge(from_id, to_id)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (g.number_of_nodes())\n",
    "print (g.number_of_edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Bipartite Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.is_bipartite(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h = nx.bipartite.projected_graph(g, heroes_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (h.number_of_nodes())\n",
    "print (h.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = nx.degree(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE\n",
    "1. Create a degree distribution plot, where xscale is logarithmic (try with log-log as well)\n",
    "2. Finish these two statements:\n",
    "        print 'Average Degree '+\n",
    "        print 'Highest Degree '+\n",
    "3. Find ut which superhero has the highest degree\n",
    "4. Repeat these tasks (1-3) with Betweeness Centrality as well\n",
    "5. Calculate and plot the Clustering Coefficient Histogram on log plot, interpet the results with finishing these satements:\n",
    "        print 'Average clustering: \n",
    "        print 'Number of nodes in fully connected neighborhood: '\n",
    "        print 'Number of bridges: '\n",
    "        print 'Network density: '\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plt.plot(list(d.values()),bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print ('Average Degree: '+str())\n",
    "print ('Highest Degree: '+str())\n",
    "\n",
    "\n",
    "print (\"Superhero with highest degree: \"+str())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BETWEENESS CENTRALITY "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print ('Average Betweeness: '+str())\n",
    "print ('Highest Betweeness: '+str())\n",
    "\n",
    "print (\"Superhero with highest betweeness: \"+str())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLUSTEING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cl="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print ('Average clustering: '+str())\n",
    "print ('Number of nodes in fully connected neighborhood: '+str())\n",
    "print ('Number of bridges: '+str())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DENSITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print ('Network Density: '+str())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. FILTERING\n",
    "\n",
    "If we want to filter somehow the network, we should use the weights of the edges. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.nodes(data=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.edges(data=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But our basic projection did not produced any weights, we just simply connected each superhero who appeared in the same comic issue. We can do it better, and calculate how many times they \"worked\" together, in that case we will have weights. Based on these weights we can filter our data to keep only the strong relations. Networkx has a few built-in weighted projections:\n",
    "\n",
    "### weighted_projected_graph(B, nodes, ratio=False)\n",
    "\n",
    "    Returns a weighted projection of B onto one of its node sets.\n",
    "\n",
    "    The weighted projected graph is the projection of the bipartite network B onto the specified nodes with weights representing the number of shared neighbors or the ratio between actual shared neighbors and possible shared \n",
    "    neighbors if ratio=True . The nodes retain their attributes and are connected in the resulting graph if they \n",
    "    have an edge to a common node in the original graph.\n",
    "    \n",
    "    \n",
    "### collaboration_weighted_projected_graph(B, nodes)\n",
    "\n",
    "    Newman’s weighted projection of B onto one of its node sets.\n",
    "\n",
    "    The collaboration weighted projection is the projection of the bipartite network B onto the specified nodes with weights assigned using Newman’s collaboration model [1]:\n",
    "\n",
    "$$w_{v,u} = \\sum_k \\frac{\\delta_{v}^{w} \\delta_{w}^{k}}{k_w - 1}$$\n",
    "\n",
    "Where v and u are nodes from the same bipartite node set, and w is a node of the opposite node set. $k_w$ is the degree of node w in the bipartite network and $\\delta_{v}^{w}$ is 1 if node v is linked to node w in the original bipartite graph or 0 otherwise.\n",
    "\n",
    "    The nodes retain their attributes and are connected in the resulting graph if have an edge to a common node in the original bipartite graph.\n",
    "[1] Scientific collaboration networks: II. Shortest paths, weighted networks, and centrality, M. E. J. Newman, Phys. Rev. E 64, 016132 (2001)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "H = nx.bipartite.collaboration_weighted_projected_graph(g, heroes_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H.edges(data=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H.nodes(data=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a weight distribution plot to see, how it loks like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How many edges we have?\n",
    "- How many nodes we have?\n",
    "- What is the density?\n",
    "- What is the minimum, maximum and avergae weight?\n",
    "- Does averga emake sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(weights), max(weights), np.mean(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H.nodes(data=True)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's filter edges and get the name of superheros and add it to the the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=\n",
    "f=nx.Graph()\n",
    "for (j,k, w) in H.edges(data=True):\n",
    "    if list(w.values())[0]>=x:\n",
    "        f.add_edge(j,k,attr_dict=w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.number_of_edges(), f.number_of_nodes(), nx.density(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "heronames=defaultdict(str)\n",
    "for (i,d) in H.nodes(data=True):\n",
    "    if i in list(f.nodes()):\n",
    "        heronames[i]=d['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nx.set_node_attributes(f, 'hero', heronames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f.nodes(data=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Clustering\n",
    "\n",
    "The community package is an extension of NetworkX, implementing the Louvain Modularity clustering, which is one of the most used algorithm in community detection (and best). More info: https://en.wikipedia.org/wiki/Louvain_Modularity\n",
    "\n",
    "**Modularity**: defined as a value between -1 and 1 that measures the density of links inside communities compared to links between communities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "part = community.best_partition(f) #calculate best parttion for each node\n",
    "values = [part.get(node) for node in f.nodes()] #get the values for each node\n",
    "counterx=Counter(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Visualization\n",
    "\n",
    "NetworkX provides basic functionality for visualizing graphs, but its main goal is to enable graph analysis rather than perform graph visualization. In the future, graph visualization functionality may be removed from NetworkX or only available as an add-on package.\n",
    "\n",
    "Proper graph visualization is hard, and we highly recommend that people visualize their graphs with tools dedicated to that task. Notable examples of dedicated and fully-featured graph visualization tools are [Cytoscape](http://www.cytoscape.org/), [Gephi](https://gephi.org/). To use these and other such tools, you should export your NetworkX graph into a format that can be read by those tools. For example, Cytoscape can read the GraphML format or edgelists (csv), and so, networkx.write_graphml(G) might be an appropriate choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos=nx.fruchterman_reingold_layout(f, scale=6.0)  #Fruchterman-Reingold force-directed algorithm\n",
    "#See more: https://en.wikipedia.org/wiki/Force-directed_graph_drawing\n",
    "nx.draw(f, pos=pos, \n",
    "        cmap = plt.get_cmap('jet'), \n",
    "        node_color = values, \n",
    "        edge_color='#A6AFB4', \n",
    "        width=0.5 ,\n",
    "        node_size=[i*4 for i in f.degree().values()], #Node size based on the number of connections\n",
    "        with_labels=False)\n",
    "plt.show()\n",
    "print ('Number of communities by the Louven method: '+str(len(counterx.keys())))\n",
    "print ('Modularity: '+str(community.modularity(part, f)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Interactive visualization to see who these guys are "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#! conda install bokeh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Bokeh](http://bokeh.pydata.org/en/latest/)\n",
    "\n",
    "\n",
    "<div class=\"frontmatter text-center\">\n",
    "<img src=\"bokeh.png\" width=\"1000px\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "from bokeh.io import push_notebook\n",
    "from bokeh.plotting import figure, output_notebook, show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a ColumnDataSource from nodes, with their names and xy positions, using the previously calcualted positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bokeh.models import ColumnDataSource\n",
    "\n",
    "nodes, nodes_coordinates = zip(*sorted(pos.items()))\n",
    "nodes_xs, nodes_ys = list(zip(*nodes_coordinates))\n",
    "heroes=[]\n",
    "for i in range(0,len(nodes)):\n",
    "    heroes.append(list(f.node[nodes[i]].values())[0])\n",
    "nodes_source =ColumnDataSource(dict(x=nodes_xs, y=nodes_ys,\n",
    "                                     hero=heroes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nodes_source.to_df().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating the plot of nodes and adding a hover with superheroes names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bokeh.plotting import show, figure\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.models import HoverTool\n",
    "\n",
    "hover = HoverTool(tooltips=[('hero', '@hero')])\n",
    "plot = figure(plot_width=800, plot_height=400,\n",
    "              tools=['tap', hover, 'box_zoom', 'reset'])\n",
    "\n",
    "plot.axis.visible = False\n",
    "plot.grid.visible = False\n",
    "\n",
    "r_circles = plot.circle('x', 'y', source=nodes_source, size=10,\n",
    "                        color='blue', level = 'overlay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the notebook server\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's see!\n",
    "show(plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding edges, with weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_edges_specs(_network, _layout):\n",
    "    d = dict(xs=[], ys=[], alphas=[])\n",
    "    weights = [d['weight'] for u, v, d in _network.edges(data=True)]\n",
    "    max_weight = max(weights)\n",
    "    calc_alpha = lambda h: 0.1 + 0.6 * (h / max_weight)\n",
    "\n",
    "    # example: { ..., ('user47', 'da_bjoerni', {'weight': 3}), ... }\n",
    "    for u, v, data in _network.edges(data=True):\n",
    "        d['xs'].append([_layout[u][0], _layout[v][0]])\n",
    "        d['ys'].append([_layout[u][1], _layout[v][1]])\n",
    "        d['alphas'].append(calc_alpha(data['weight']))\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines_source=ColumnDataSource(data=get_edges_specs(f, pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines_source.to_df().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r_lines = plot.multi_line('xs', 'ys', source=lines_source, line_width=1.5, alpha='alphas',\n",
    "                          color='navy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is a helper \"function\" to not plot edge attributes, we only keep the attributes of the circles=nodes\n",
    "from bokeh.models import GlyphRenderer, Circle\n",
    "grs = r_circles.select(dict(type=GlyphRenderer))\n",
    "for glyph in grs:\n",
    "    if isinstance(glyph.glyph, Circle):\n",
    "        circle_renderer = glyph\n",
    "hover.renderers = [circle_renderer]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see the network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "show(plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The chart is not so pretty, we should add node sizes, and colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sizes\n",
    "centrality =\\\n",
    "    nx.degree(f)\n",
    "# first element are nodes again\n",
    "_, nodes_centrality = zip(*sorted(centrality.items()))\n",
    "max_centraliy = max(nodes_centrality)\n",
    "nodes_source.add([7 + 20 * t / max_centraliy\n",
    "                  for t in nodes_centrality],\n",
    "                 'centrality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And partition to be sexy\n",
    "partition = community.best_partition(f)\n",
    "p_, nodes_community = zip(*sorted(partition.items()))\n",
    "nodes_source.add(nodes_community, 'community')\n",
    "community_colors = ['#e41a1c','#377eb8','#4daf4a','#984ea3','#ff7f00','#ffff33','#a65628', '#b3cde3','#ccebc5','#decbe4','#fed9a6','#ffffcc','#e5d8bd','#fddaec','#1b9e77','#d95f02','#7570b3','#e7298a','#66a61e','#e6ab02','#a6761d','#666666']\n",
    "nodes_source.add([community_colors[t % len(community_colors)]\n",
    "                  for t in nodes_community],\n",
    "                 'community_color')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adding the computed attributes to the plot\n",
    "r_circles.glyph.size = 'centrality'\n",
    "r_circles.glyph.fill_color = 'community_color'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fina plot, let's play with it!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "show(plot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
